{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost is a library 2014 that is build on gradient boosting.\n",
        "\n",
        "Algorithms are data specific/scenerio specfic.\n",
        "\n",
        "XGBoost is combination of gradient boosting and software engineering concepts.\n",
        "\n",
        "\n",
        "**History**\n",
        "\n",
        "\n",
        "\n",
        "1.   Early days\n",
        "\n",
        "Y gradient boosting? It is flexible. can use any loss fun that is differentiable. It's performance, robustness, and can handle missing values internally.\n",
        "\n",
        "2014 paper: XGBoost: A highly Scalable ML Algorithm\n",
        "\n",
        "\n",
        "2.   Middle\n",
        "\n",
        "In 2016, out of 29 winning model on Kaggle, 16 use XGBoost. That increase it's popularity.\n",
        "\n",
        "3.   Open source\n",
        "\n",
        "Then it gets opensourced. Enhance features, optimizers, multiple support in diff languages.\n",
        "\n",
        "\n",
        "**XGBoost Features**\n",
        "\n",
        "Three main concerns were kept in mind while build this library.\n",
        "1. perfoemance\n",
        "2. speed\n",
        "3. Flexibilty\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k5CjTWPmf1zm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3rMV9rKfqJm"
      },
      "outputs": [],
      "source": []
    }
  ]
}